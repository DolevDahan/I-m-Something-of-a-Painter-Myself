# ğŸ¨ Photo-to-Monet Image Translation using CycleGAN & Contrastive Learning

This repository contains our final project for the course  
**"Deep Learning and Its Application to Signal and Image Processing and Analysis"**,  
focused on unpaired image translation from photographs to Monet-style paintings.

---

## ğŸ“Œ Project Overview

### ğŸ¯ Objective

Develop a model that translates real-world **photos** into the artistic style of **Claude Monet**,  
while preserving the original image structure.

We implemented and evaluated two models:
- **Model 1**: Vanilla CycleGAN - https://arxiv.org/abs/1703.10593
- **Model 2**: CycleGAN & PatchNCE-based model

---

## ğŸ§  Key Challenges

- Small Monet dataset (only 300 images)
- No paired data between Photo and Monet domains
- Achieving both realism and semantic preservation

---

## ğŸ—‚ï¸ Dataset

| Class  | Count | Type | Size          |
|--------|-------|------|----------------|
| Photo  | 7,038 | RGB  | 256Ã—256        |
| Monet  | 300   | RGB  | 256Ã—256        |

- Training set: 200 random images from each class (with seeds 42, 123, 2025)
- Test set: 893 Monet paintings from [TFDS Monet Dataset](https://www.kaggle.com/datasets/dimitreoliveira/monet-paintings-jpg-berkeley)

---

## ğŸ—ï¸ Model Architectures

### ğŸŒ€ Model 1 â€“ Vanilla CycleGAN

- Two generators (G_AB, G_BA) and two discriminators (D_A, D_B)
- Uses:
  - **Cycle-consistency loss**
  - **Identity loss**
  - **Adversarial loss (LSGAN)**

#### Generator Loss:











---

### âœ¨ Model 2 â€“ PatchNCE (Contrastive Learning)

- Removed cycle and identity losses
- Introduced **PatchNCE loss** for contrastive feature alignment
- Generator encourages semantic similarity between input & output patches

#### Generator Loss:




Default: `Î»_NCE = 1.0`

---

## ğŸ“ Evaluation â€“ MiFID

We used the **MiFID** (Memorization-informed FID) metric, which penalizes overfitting.  
It is computed between generated Monet-style images and a separate Monet test set.

---

## ğŸ“Š Results Summary

| Model        | Mean MiFID | Std. Deviation |
|--------------|------------|----------------|
| Vanilla      | 91.537     | 3.456          |
| PatchNCE     | 78.448     | 2.987          |

---

## ğŸ§ª Ablation Study â€“ PatchNCE Weight (Î»)

To evaluate the effect of the PatchNCE loss on training, we varied `Î»_NCE`:

| Î»_NCE | MiFID   | Feature Distance |
|--------|---------|------------------|
| 1.0    | 76.711  | 0.254            |
| 0.35   | 80.272  | 0.257            |
| 0.01   | 293.404 | 0.353            |

**Conclusion**:  
High contrastive supervision (Î» = 1.0) is crucial for semantic alignment and stable training.  
Low Î» leads to poor generalization and unstable convergence.

---

## ğŸ–¼ï¸ Sample Outputs

All qualitative results can be found in the `outputs/` folder:

- `positive_performance_model2.png`
- `both_good.png`
- `model1_good_model2_bad.png`
- `model2_good_model1_bad.png`
- `exapmle_lamba035.png`
- `exapmle_lamba001.png`

---

## âš™ï¸ Training Details

| Hyperparameter       | Value                     |
|----------------------|---------------------------|
| Epochs               | 100 (with linear decay)   |
| Batch size           | 4                         |
| Learning rate        | 0.0002                    |
| Optimizer            | Adam (Î²1=0.5, Î²2=0.999)   |
| GAN Loss Type        | Least Squares GAN (LSGAN) |
| PatchNCE Temperature | 0.07                      |
| Contrastive Patches  | 256                       |
| Feature Layers       | 0, 4, 8, 12, 16           |

---

## ğŸ“‚ References

- [Kaggle GAN Competition](https://www.kaggle.com/competitions/gan-getting-started/data)
- [TFDS Monet Dataset](https://www.kaggle.com/datasets/dimitreoliveira/monet-paintings-jpg-berkeley)
- [MiFID Evaluation Metric](https://www.kaggle.com/competitions/gan-getting-started/overview/evaluation)

---

## ğŸ‘¥ Authors

- **Dolev Dahan** â€“ 209406768
- **Ronel Davidov** â€“ 209405216  


ğŸ“« Contact us at:  
`dahandol@post.bgu.ac.il`, `davidovr@post.bgu.ac.il`.

